#kafka参数
kafka.brokers=localhost:9092
kafka.group.id=metric-group
kafka.zookeeper.connect=localhost:2181
metrics.topic=metric
stream.parallelism=5
stream.checkpoint.interval=1000
stream.checkpoint.enable=false
kafka.sink.brokers=localhost:9092
kafka.sink.topic=metric-local
#ES参数
cluster.name = zzh-es-cluster
elasticsearch.hosts=localhost:9300
#批量写入时的最大写入条数
bulk.flush.max.actions=5
stream.sink.parallelism=5
#用来表示是否开启重试机制
bulk.flush.backoff.enable=true
#重试策略，有两种：EXPONENTIAL 指数型（表示多次重试之间的时间间隔按照指数方式进行增长）、CONSTANT 常数型（表示多次重试之间的时间间隔为固定常数）
bulk.flush.backoff.type = EXPONENTIAL
#进行重试的时间间隔
bulk.flush.backoff.delay = 1000
#失败重试的次数
bulk.flush.backoff.retries=5
#批量写入时的最大数据量
bulk.flush.max.size.mb:10
#批量写入的时间间隔，配置后则会按照该时间间隔严格执行，无视上面的两个批量写入配置
bulk.flush.interval.ms: